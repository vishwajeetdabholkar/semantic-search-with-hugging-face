{
"name": "improved-semantic-search-notebook",
"display_name": "Improved Semantic Search Notebook",
"content": {
"cells": [
{
"cell_type": "markdown",
"source": "# Semantic Search with Hugging Face Models and Datasets\n\nThis notebook demonstrates conducting semantic search on SingleStoreDB using Hugging Face models and datasets. We'll utilize embeddings and SQL for accurate search results."
},
{
"cell_type": "markdown",
"source": "## Setup\n\n1. Create a workspace in your workspace group.\n2. Set up the semantic_search database."
},
{
"cell_type": "code",
"source": "%%sql\nDROP DATABASE IF EXISTS semantic_search;\nCREATE DATABASE semantic_search;"
},
{
"cell_type": "markdown",
"source": "## Install and Import Libraries"
},
{
"cell_type": "code",
"source": "!pip3 install --upgrade sentence-transformers torch tensorflow datasets pandarallel --quiet"
},
{
"cell_type": "code",
"source": "import json\nimport ibis\nimport numpy as np\nimport pandas as pd\nimport sqlalchemy as sa\nimport singlestoredb as s2\nimport torch\nfrom datasets import load_dataset\nfrom pandarallel import pandarallel\nfrom transformers import AutoTokenizer, AutoModel\npandarallel.initialize(nb_workers=2, progress_bar=True)"
},
{
"cell_type": "markdown",
"source": "## Load Sentence Transformer Model and Define Embedding Function"
},
{
"cell_type": "code",
"source": "model_name = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"\nmodel = AutoModel.from_pretrained(model_name)\ntokenizer = AutoTokenizer.from_pretrained(model_name)"
},
{
"cell_type": "code",
"source": "def get_embedding(sentence: str) -> np.ndarray:\n inputs = tokenizer(sentence, padding=True, truncation=True, return_tensors="pt")\n with torch.no_grad():\n embedding = model(**inputs).last_hidden_state.mean(dim=1).squeeze().tolist()\n return np.array(embedding, dtype='<f4')"
},
{
"cell_type": "markdown",
"source": "## Load Dataset and Sample Reviews"
},
{
"cell_type": "code",
"source": "dataset = load_dataset("ajaykarthick/imdb-movie-reviews")\ndataframe = dataset["train"].to_pandas()\nrandom_sample = dataframe.sample(n=100)"
},
{
"cell_type": "markdown",
"source": "## Generate Embeddings for Reviews"
},
{
"cell_type": "code",
"source": "random_sample['review_embeddings'] = random_sample['review'].parallel_apply(get_embedding)"
},
{
"cell_type": "markdown",
"source": "## Insert Data into SingleStoreDB"
},
{
"cell_type": "code",
"source": "random_sample.to_sql('reviews', s2.create_engine().connect(), if_exists='replace', index=False, dtype=dict(review_embeddings=sa.LargeBinary))"
},
{
"cell_type": "markdown",
"source": "## Semantic Search"
},
{
"cell_type": "code",
"source": "searchstring = input('Please enter a search string:')\nsearch_embedding = get_embedding(searchstring).tobytes().hex()\nresults = %sql SELECT review, DOT_PRODUCT(review_embeddings, X'{{search_embedding}}') AS Score FROM reviews ORDER BY Score DESC LIMIT 5;\nfor i, res in enumerate(results):\n print(f'{i + 1}: {res[0]} Score: {res[1]:.2f}')"
},
{
"cell_type": "markdown",
"source": "## Clean Up"
},
{
"cell_type": "code",
"source": "%%sql\nDROP DATABASE semantic_search;"
}
],
"metadata": {
"kernelspec": {
"display_name": "Python 3",
"language": "python",
"name": "python3"
}
},
"nbformat": 4,
"nbformat_minor": 5
}
}
